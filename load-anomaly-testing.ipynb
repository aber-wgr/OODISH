{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder Anomaly Testing\n",
    "===\n",
    "\n",
    "This is rebuilt from the \"Collecting Network Statistics\" notebook. The goal of this notebook is to collect together a set of in-distribution and out-of-distribution images and confirm that the model can distinguish them with a high degree of accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin by importing our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import math\n",
    "\n",
    "from pytorch_msssim import ssim,ms_ssim,SSIM\n",
    "from model import SplitAutoencoder,ExtensibleEncoder,ExtensibleDecoder\n",
    "from CustomDataSet import CustomDataSet,CustomDataSetWithError\n",
    "from GaussianNoise import AddGaussianNoiseAndRescale,Rescale\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,auc\n",
    "\n",
    "import GPUtil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set our seed and other configurations for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "#seed = 2662\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "basis = \"holdout\"\n",
    "distribution = \"screening\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    platform = \"cuda\"\n",
    "else:\n",
    "    platform = \"cpu\"\n",
    "#platform = \"cpu\"\n",
    "print(platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the batch size, the number of training epochs, and the learning rate. Batch size has to be reasonably low as we can't fit a huge number of these images into VRAM on my laptop.\n",
    "\n",
    "Image size can be set here as I'm automatically resizing the images in my extraction code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "height = 256\n",
    "\n",
    "image_size = width * height\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "#meta-parameters\n",
    "l2_decay = 0.0\n",
    "dropout_rate = 0.1\n",
    "code_sides = [20]\n",
    "convolution_filters = 32\n",
    "\n",
    "model_extension = str(width) + \"_\" + str(code_sides[0]) + \"_\" + str(convolution_filters) + \"_\" + str(dropout_rate) + \"_\" + str(l2_decay)\n",
    "full_extension = \"_\" + basis + \"_\" + distribution + \"_\" + model_extension\n",
    "\n",
    "model_path = \"../../Data/OPTIMAM_NEW/model\" + full_extension + \".pt\"\n",
    "\n",
    "#image_count = 500\n",
    "image_count = -1\n",
    "\n",
    "validation_split = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Base Distribution Information\n",
    "\n",
    "First we run the model on the entire original distribution and gather statistics on the loss values, encodings etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor,Normalize\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(0.0,65535.0)\n",
    "    ])\n",
    "\n",
    "if distribution==\"screening\":\n",
    "    root_dir = \"../../Data/OPTIMAM_NEW/png_images/casewise/ScreeningMammography/\" + str(width)\n",
    "else:\n",
    "    root_dir = \"../../Data/OPTIMAM_NEW/png_images/lesions\"\n",
    "train_dataset = CustomDataSet(root_dir, transform)\n",
    "\n",
    "if (image_count == -1):\n",
    "    train_dataset_subset = train_dataset\n",
    "    image_count = len(train_dataset)\n",
    "else:\n",
    "    train_dataset_subset = torch.utils.data.Subset(train_dataset, numpy.random.choice(len(train_dataset), image_count, replace=False))\n",
    "\n",
    "train_subset_idx = np.random.choice(len(train_dataset), int(image_count * validation_split), replace=False)\n",
    "\n",
    "n = np.arange(len(train_dataset))\n",
    "mask = np.ones(len(train_dataset), dtype=bool)\n",
    "mask[train_subset_idx] = False\n",
    "holdout_subset_idx = n[mask]\n",
    "\n",
    "dataset_size = len(train_dataset_subset)\n",
    "      \n",
    "t_subset = torch.utils.data.Subset(train_dataset_subset, train_subset_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    t_subset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "h_subset = torch.utils.data.Subset(train_dataset_subset, holdout_subset_idx)\n",
    "\n",
    "holdout_loader = torch.utils.data.DataLoader(\n",
    "    h_subset, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2934 1524 1451 ... 2597 3421 2618]\n",
      "[  26   27   60   66   91  103  109  112  123  169  190  211  232  406\n",
      "  422  430  468  470  480  496  520  526  558  559  562  570  575  580\n",
      "  603  678  685  697  703  704  705  716  728  741  780  799  825  843\n",
      "  858  911  944 1007 1016 1050 1061 1081 1110 1118 1137 1193 1229 1237\n",
      " 1255 1265 1302 1354 1365 1385 1393 1409 1420 1457 1469 1470 1498 1513\n",
      " 1538 1546 1565 1581 1594 1607 1625 1636 1640 1685 1718 1744 1750 1753\n",
      " 1788 1805 1832 1859 1870 1891 1919 1932 1934 1948 1979 2000 2019 2022\n",
      " 2023 2039 2044 2052 2100 2145 2150 2176 2183 2184 2194 2228 2258 2282\n",
      " 2326 2336 2337 2367 2369 2377 2449 2481 2484 2503 2523 2529 2539 2545\n",
      " 2552 2595 2610 2619 2652 2664 2671 2677 2678 2717 2720 2740 2820 2827\n",
      " 2894 2896 2908 2928 2941 2953 2972 2997 3003 3004 3007 3019 3021 3081\n",
      " 3087 3113 3118 3165 3192 3197 3203 3205 3225 3232 3238 3279 3281 3298\n",
      " 3334 3352 3388 3391 3405 3408 3417 3429 3511 3520 3521 3568 3578 3592\n",
      " 3641 3663]\n"
     ]
    }
   ],
   "source": [
    "print(train_subset_idx)\n",
    "print(holdout_subset_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use gpu if available\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(platform)\n",
    "\n",
    "code_size = code_sides[0] * code_sides[0]\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "features = [None] * len(t_subset)\n",
    "losses = [None] * len(t_subset)\n",
    "encodings = [None] * len(t_subset)\n",
    "outputs = [None] * len(t_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../Data/OPTIMAM_NEW/model_holout_screening_256_20_32_0.1_0.0.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-848e78ceead5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# reload the saved model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Data/OPTIMAM_NEW/model_holout_screening_256_20_32_0.1_0.0.pt'"
     ]
    }
   ],
   "source": [
    "# reload the saved model\n",
    "model = torch.load(model_path,map_location=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run our autoencoder on the entire dataset and store the encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for batch_features in train_loader:\n",
    "        # load it to the active device\n",
    "        batch_features = batch_features.to(device)\n",
    "\n",
    "        features[count] = batch_features.cpu()\n",
    "        \n",
    "        # compute reconstructions\n",
    "        code = model.encoder(batch_features)\n",
    "        output = model.decoder(code)\n",
    "        \n",
    "        outputs[count] = output.cpu()\n",
    "        \n",
    "        code_reshaped = code.detach().cpu().numpy()[0]\n",
    "        code_reshaped.reshape(code_size)\n",
    "\n",
    "        encodings[count] = code_reshaped\n",
    "\n",
    "        # compute training reconstruction loss\n",
    "        error_criterion = criterion(output,batch_features)\n",
    "\n",
    "        losses[count] = error_criterion.cpu().numpy()\n",
    "\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And calculate the encoding statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_n = np.stack(encodings)\n",
    "encodings_t = torch.from_numpy(encodings_n)\n",
    "encodings_mean = torch.mean(encodings_t,0)\n",
    "\n",
    "encodings_mean_np = encodings_mean.numpy()\n",
    "print(encodings_n)\n",
    "encodings_covariance = np.cov(encodings_n.T)\n",
    "print(encodings_covariance)\n",
    "encodings_inv_covariance = np.linalg.inv(encodings_covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_min = np.amin(losses)\n",
    "mse_max = np.amax(losses)\n",
    "mse_mean = np.mean(losses)\n",
    "mse_std = np.std(losses)\n",
    "print(\"MSE Min/Mean/Max/SD:\" + str(mse_min) + \"/\" + str(mse_mean) + \"/\" + str(mse_max) + \"/\" + str(mse_std)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_n = np.stack(features)\n",
    "outputs_n = np.stack(outputs)\n",
    "print(features_n.shape)\n",
    "print(outputs_n.shape)\n",
    "\n",
    "pre_ssims = [None] * len(encodings)\n",
    "\n",
    "ssim_module = SSIM(data_range=1.0, size_average=False, channel=3)\n",
    "\n",
    "for i in range(len(encodings)):\n",
    "    features_s = features_n[i].reshape(1,1,height,width).repeat(3,1)\n",
    "    outputs_s = outputs_n[i].reshape(1,1,height,width).repeat(3,1)\n",
    "    ssim_f = ssim_module(torch.from_numpy(features_s), torch.from_numpy(outputs_s))\n",
    "    pre_ssims[i] = ssim_f.item()\n",
    "    \n",
    "ssim_min = np.amin(pre_ssims)\n",
    "ssim_max = np.amax(pre_ssims)\n",
    "ssim_mean = np.mean(pre_ssims)\n",
    "ssim_sd = np.std(pre_ssims)\n",
    "print(\"SSIM Min/Mean/Max/SD:\" + str(ssim_min) + \"/\" + str(ssim_mean) + \"/\" + str(ssim_max) + \"/\" + str(ssim_sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the compiled statistics to an excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    np_losses = np.asarray(losses)\n",
    "    np_pre_ssims = np.asarray(pre_ssims)\n",
    "    np_compiled = np.concatenate((np_losses[:, np.newaxis], encodings), axis=1)\n",
    "\n",
    "    suffix = full_extension\n",
    "    \n",
    "    np.savetxt('base_encodings' + suffix + '.csv', encodings, delimiter=',',fmt='%10.5f',newline='\\n')\n",
    "    np.savetxt('base_losses' + suffix + '.csv', np_losses, delimiter=',',fmt='%10.5f',newline='\\n')\n",
    "    np.savetxt('base_ssim' + suffix + '.csv', np_pre_ssims, delimiter=',',fmt='%10.5f',newline='\\n')\n",
    "    np.savetxt('base_combined' + suffix + '.csv', np_compiled, delimiter=',',fmt='%10.5f',newline='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarials\n",
    "\n",
    "We have 2 Datasets (mammographic and non-mammographic) and 3 DataLoaders - Clean Mammo, Distorted Mammo, and Non-Mammo. The goal here is to build an analogously large set of OOD images and test to what degree the autoencoder is capable of detecting the distortions.\n",
    "\n",
    "The first method for doing this builds a large set of all the datasets classified into In-Distribution and Out-Of-Distribution and determine the accuracy rating of the model as a classifier. The second generates a set of distorted mammographic images at specified distances from the distribution, along with a value roughly analogous to that distortion level. This second method is intended to determine the range in distribution space at which the model becomes able to distinguish, as well as the degree of \"grey area\" between in and out of distribution (as detected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    trigger_chance = 0.4\n",
    "\n",
    "    PIL_transforms = torchvision.transforms.RandomApply([\n",
    "        torchvision.transforms.RandomAffine(degrees=10,translate=(0.2,0.2),shear=25),\n",
    "        torchvision.transforms.RandomVerticalFlip(),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "#        torchvision.transforms.GaussianBlur(kernel_size=3)\n",
    "        ],p=trigger_chance)\n",
    "    \n",
    "    tensor_transforms = torchvision.transforms.RandomApply([\n",
    "        torchvision.transforms.RandomErasing(p=1.0,value=torch.rand(1).item()),\n",
    "        torchvision.transforms.Lambda(lambda x : x + (torch.randn_like(x) * 0.001))\n",
    "#        AddGaussianNoiseAndRescale(0.0,0.2)\n",
    "        ],p=trigger_chance)\n",
    "\n",
    "    adversarial_transform = torchvision.transforms.Compose([        \n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(0.0,65535.0),\n",
    "        PIL_transforms,\n",
    "        tensor_transforms,\n",
    "        Rescale()\n",
    "        ])\n",
    "   \n",
    "    adversarial_image_count = image_count\n",
    "    adversarial_dataset = CustomDataSetWithError(root_dir, adversarial_transform)\n",
    "    \n",
    "    if(basis == \"holdout\"): \n",
    "        a_subset = torch.utils.data.Subset(adversarial_dataset, holdout_subset_idx)\n",
    "    else:\n",
    "        a_subset = torch.utils.data.Subset(adversarial_dataset, train_subset_idx)\n",
    "\n",
    "    adversarial_loader = torch.utils.data.DataLoader(\n",
    "        a_subset,shuffle=True\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the first (mixed) set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    adversarial_iterator = iter(adversarial_loader)\n",
    "    genuine_iterator = iter(holdout_loader)\n",
    "    mixed_set_scale = 300\n",
    "    \n",
    "    mixed_set = []\n",
    "    mixed_set_np = []\n",
    "    mixed_class_set = []\n",
    "    mixed_error_set = []\n",
    "    for i in range(mixed_set_scale):\n",
    "        r = torch.rand(1)\n",
    "        if(r.item() > 0.5):\n",
    "            error = 0.0\n",
    "            while(error==0.0):\n",
    "                try:\n",
    "                    adversarial_t = next(adversarial_iterator)\n",
    "                    adversarial = adversarial_t[0].cpu()\n",
    "                    adversarial_np = adversarial.numpy().reshape(width,height)\n",
    "                    error = adversarial_t[1].item()\n",
    "                except StopIteration:\n",
    "                    adversarial_iterator = iter(adversarial_loader)\n",
    "            mixed_class_set.append(1) # positive class, since we're trying to detect adversarials\n",
    "            mixed_set_np.append(adversarial_np)\n",
    "            mixed_set.append(adversarial)\n",
    "            mixed_error_set.append(error)\n",
    "            print(\"Positive: Min \" + str(np.amin(adversarial_np)) + \" Max \" + str(np.amax(adversarial_np)) + \" Error \" + str(error))\n",
    "        else:\n",
    "            genuine = next(genuine_iterator).cpu()\n",
    "            genuine_np = genuine.numpy().reshape(width,height)\n",
    "            mixed_class_set.append(0) # negative class\n",
    "            mixed_set.append(genuine)\n",
    "            mixed_set_np.append(genuine_np)\n",
    "            mixed_error_set.append(0.0) # genuine, so no drift\n",
    "            print(\"Negative: Min \" + str(np.amin(genuine_np)) + \" Max \" + str(np.amax(genuine_np)) + \" Error 0.0\")\n",
    "        \n",
    "    mixed_code_set = []\n",
    "    mixed_code_np_set = []\n",
    "    mixed_reconstruction_set = []\n",
    "    mixed_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the model on the mixed set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for mixed_item in mixed_set:\n",
    "        mixed_example = mixed_item.to(device)\n",
    "        \n",
    "        n_code = model.encoder(mixed_example)\n",
    "        reconstruction = model(mixed_example)\n",
    "        \n",
    "        mixed_code_set.append(n_code.cpu())\n",
    "        mixed_code_np_set.append(n_code.cpu().numpy())\n",
    "        mixed_reconstruction_set.append(reconstruction.cpu())\n",
    "        \n",
    "        error_criterion = criterion(reconstruction,mixed_example)\n",
    "        loss = error_criterion.cpu().numpy()\n",
    "        mixed_losses.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, measure the loss and feature statistics for the adversarials:            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSE):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First calculate the MSE for all the reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_losses_np = np.asarray(mixed_losses)\n",
    "post_mse_min = np.amin(mixed_losses_np)\n",
    "post_mse_max = np.amax(mixed_losses_np)\n",
    "post_mse_mean = np.mean(mixed_losses_np)\n",
    "post_mse_std = np.std(mixed_losses_np)\n",
    "print(\"Prediction MSE Min/Mean/Max/SD:\" + str(post_mse_min) + \"/\" + str(post_mse_mean) + \"/\" + str(post_mse_max) + \"/\" + str(post_mse_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And attempt to predict classes based on MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_threshold = mse_mean + (2 * mse_std)\n",
    "\n",
    "predicted_class = []\n",
    "for i in range(mixed_set_scale):\n",
    "    if(mixed_losses_np[i]<mse_threshold):\n",
    "        predicted_class.append(0) # distribution\n",
    "    else:\n",
    "        predicted_class.append(1) # adversarial\n",
    "\n",
    "mixed_class_np = np.asarray(mixed_class_set)\n",
    "predicted_class_np = np.asarray(predicted_class)\n",
    "print(mixed_class_np)\n",
    "print(predicted_class_np)\n",
    "\n",
    "tp = np.sum(mixed_class_np * predicted_class_np)\n",
    "tn = np.sum((1 - mixed_class_np) * (1 - predicted_class_np))\n",
    "fp = np.sum((1 - mixed_class_np) * predicted_class_np)\n",
    "fn = np.sum(mixed_class_np * (1 - predicted_class_np))\n",
    "\n",
    "hits = tn + tp\n",
    "accuracy = hits / mixed_set_scale\n",
    "print(\"Accuracy:\" + str(accuracy))\n",
    "\n",
    "precision = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "\n",
    "f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "print(\"Precision:\" + str(precision))\n",
    "print(\"Recall:\" + str(recall))\n",
    "print(\"F1:\" + str(f1_score))\n",
    "\n",
    "fails = np.where(mixed_class_np != predicted_class_np)\n",
    "print(fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresh = roc_curve(mixed_class_np, mixed_losses_np)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(fpr)\n",
    "print(tpr)\n",
    "print(thresh)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('MSE basis ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "out_path = \"mse_roc_graph_output\" + full_extension + \".eps\"\n",
    "plt.savefig(out_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STRUCTURAL SIMILARITY INDEX (SSIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate RGB versions of the base and recreated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_set_s = np.stack(mixed_set).reshape(mixed_set_scale,1,height,width).repeat(3,1)\n",
    "mixed_recon_s = np.stack(mixed_reconstruction_set).reshape(mixed_set_scale,1,height,width).repeat(3,1)\n",
    "print(mixed_set_s.shape)\n",
    "print(mixed_recon_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use that for Structural Similarity Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_t = ssim(torch.from_numpy(mixed_set_s), torch.from_numpy(mixed_recon_s), data_range=1.0, size_average = False)\n",
    "ms_ssim_t = ms_ssim(torch.from_numpy(mixed_set_s), torch.from_numpy(mixed_recon_s), data_range=1.0, size_average = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_ssim_min = np.amin(ssim_t.numpy())\n",
    "post_ssim_max = np.amax(ssim_t.numpy())\n",
    "post_ssim_mean = np.mean(ssim_t.numpy())\n",
    "post_ssim_std = np.std(ssim_t.numpy())\n",
    "print(\"Prediction SSIM Min/Mean/Max/SD:\" + str(post_ssim_min) + \"/\" + str(post_ssim_mean) + \"/\" + str(post_ssim_max) + \"/\" + str(post_ssim_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    np_post_losses = np.asarray(mixed_losses_np)\n",
    "    np_post_ssims = np.asarray(ssim_t)\n",
    "    np_distances = np.asarray(mixed_error_set)\n",
    "    \n",
    "    suffix = full_extension\n",
    "    \n",
    "    np.savetxt('mixed_losses' + suffix + '.csv', np_post_losses, delimiter=',',fmt='%10.5f',newline='\\n')\n",
    "    np.savetxt('mixed_ssim' + suffix + '.csv', np_post_ssims, delimiter=',',fmt='%10.5f',newline='\\n')\n",
    "    np.savetxt('mixed_distance' + suffix + '.csv', np_distances, delimiter=',',fmt='%10.5f',newline='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to predict the class based on the SSIM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_threshold = ssim_mean - (2 * ssim_sd)\n",
    "#ssim_threshold = ssim_min\n",
    "predicted_class_ssim = []\n",
    "for i in range(mixed_set_scale):\n",
    "    if(ssim_t[i]>ssim_threshold):\n",
    "        predicted_class_ssim.append(0) # distribution\n",
    "    else:\n",
    "        predicted_class_ssim.append(1) # adversarial\n",
    "\n",
    "predicted_class_ssim_np = np.asarray(predicted_class_ssim)\n",
    "print(mixed_class_np)\n",
    "print(predicted_class_ssim_np)\n",
    "tp_ssim = np.sum(mixed_class_np * predicted_class_ssim_np)\n",
    "tn_ssim = np.sum((1 - mixed_class_np) * (1 - predicted_class_ssim_np))\n",
    "fp_ssim = np.sum((1 - mixed_class_np) * predicted_class_ssim_np)\n",
    "fn_ssim = np.sum(mixed_class_np * (1 - predicted_class_ssim_np))\n",
    "\n",
    "hits_ssim = tn_ssim + tp_ssim\n",
    "accuracy_ssim = hits_ssim / mixed_set_scale\n",
    "print(\"Accuracy:\" + str(accuracy_ssim))\n",
    "\n",
    "precision_ssim = tp_ssim / (tp_ssim+fp_ssim)\n",
    "recall_ssim = tp_ssim / (tp_ssim+fn_ssim)\n",
    "\n",
    "f1_score_ssim = 2 * ((precision_ssim * recall_ssim) / (precision_ssim + recall_ssim))\n",
    "\n",
    "print(\"Precision:\" + str(precision_ssim))\n",
    "print(\"Recall:\" + str(recall_ssim))\n",
    "print(\"F1:\" + str(f1_score_ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence value for roc curve is 1-SSIM errpr (ie, for extremely high error we are less sure)\n",
    "fpr, tpr, thresh = roc_curve(mixed_class_np, 1 - ssim_t)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(fpr)\n",
    "print(tpr)\n",
    "print(thresh)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('SSIM Basis ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "out_path = \"ssim_roc_graph_output\" + full_extension + \".eps\"\n",
    "plt.savefig(out_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mahalanobis Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the Mahalanobis distance for every result in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mahalanobis_set = []\n",
    "    for i in range(len(mixed_code_set)):\n",
    "        code = mixed_code_np_set[i]\n",
    "        x_minus_mu =  code - encodings_mean_np\n",
    "        left_term = np.dot(x_minus_mu, encodings_inv_covariance)\n",
    "        mahal = np.dot(left_term, x_minus_mu.T)\n",
    "        m = mahal.diagonal()\n",
    "        \n",
    "        mahalanobis_set.append(m)\n",
    "    mahalanobis_set_np = np.stack(mahalanobis_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahal_threshold = 240\n",
    "#ssim_threshold = ssim_min\n",
    "predicted_class_mahal = []\n",
    "for i in range(mixed_set_scale):\n",
    "    if(mahalanobis_set[i]<mahal_threshold):\n",
    "        predicted_class_mahal.append(0) # distribution\n",
    "    else:\n",
    "        predicted_class_mahal.append(1) # adversarial\n",
    "\n",
    "predicted_class_mahal_np = np.asarray(predicted_class_mahal)\n",
    "print(mixed_class_np)\n",
    "print(predicted_class_mahal_np)\n",
    "tp_mahal = np.sum(mixed_class_np * predicted_class_mahal_np)\n",
    "tn_mahal = np.sum((1 - mixed_class_np) * (1 - predicted_class_mahal_np))\n",
    "fp_mahal = np.sum((1 - mixed_class_np) * predicted_class_mahal_np)\n",
    "fn_mahal = np.sum(mixed_class_np * (1 - predicted_class_mahal_np))\n",
    "\n",
    "hits_mahal = tn_mahal + tp_mahal\n",
    "accuracy_mahal = hits_mahal / mixed_set_scale\n",
    "print(\"Accuracy:\" + str(accuracy_mahal))\n",
    "\n",
    "precision_mahal = tp_mahal / (tp_mahal+fp_mahal)\n",
    "recall_mahal = tp_mahal / (tp_mahal+fn_mahal)\n",
    "\n",
    "f1_score_mahal = 2 * ((precision_mahal * recall_mahal) / (precision_mahal + recall_mahal))\n",
    "\n",
    "print(\"Precision:\" + str(precision_mahal))\n",
    "print(\"Recall:\" + str(recall_mahal))\n",
    "print(\"F1:\" + str(f1_score_mahal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresh = roc_curve(mixed_class_np, mahalanobis_set)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Mahalanobis Basis ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "out_path = \"mahal_roc_graph_output\" + full_extension + \".eps\"\n",
    "plt.savefig(out_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the first 10 results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mixed_set_g = np.stack(mixed_set).reshape(mixed_set_scale,height,width,1).repeat(3,3)\n",
    "    mixed_recon_g = np.stack(mixed_reconstruction_set).reshape(mixed_set_scale,height,width,1).repeat(3,3)\n",
    "    print(mixed_set_g.shape)\n",
    "    print(mixed_recon_g.shape)\n",
    "\n",
    "    #number = mixed_set_scale\n",
    "    number = 10\n",
    "    plt.figure(figsize=(25, 9))\n",
    "    for index in range(number):\n",
    "        # display original\n",
    "        ax = plt.subplot(3, number, index + 1)\n",
    "        test_examples = mixed_set_g\n",
    "        copyback = test_examples[index]\n",
    "        print(copyback.shape)\n",
    "        plt.imshow(copyback)\n",
    "        #plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display codes\n",
    "        ax = plt.subplot(3, number, index + number + 1)\n",
    "        codes = mixed_code_set\n",
    "        code_copyback = codes[index].cpu()\n",
    "        plt.imshow(code_copyback.reshape(code_sides[0],code_sides[0]))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(3, number, index + (number*2) + 1)\n",
    "        reconstruction = mixed_recon_g\n",
    "        recon_copyback = reconstruction[index]\n",
    "        plt.imshow(recon_copyback)\n",
    "        #plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    out_path = \"adv_output\" + full_extension + \".png\"\n",
    "    plt.savefig(out_path)\n",
    "    out_path = \"adv_output\" + full_extension + \".eps\"\n",
    "    plt.savefig(out_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the failures from the MSE calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    if(len(fails[0])<30):\n",
    "        #number = mixed_set_scale\n",
    "        number = len(fails[0])\n",
    "        plt.figure(figsize=(25, 9))\n",
    "        for index in range(number):\n",
    "            image_index = fails[0][index]\n",
    "            # display original\n",
    "            ax = plt.subplot(3, number, index + 1)\n",
    "            test_examples = mixed_set_g\n",
    "            copyback = test_examples[image_index]\n",
    "            print(copyback.shape)\n",
    "            plt.imshow(copyback)\n",
    "            #plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "            # display codes\n",
    "            ax = plt.subplot(3, number, index + number + 1)\n",
    "            codes = mixed_code_set\n",
    "            code_copyback = codes[image_index].cpu()\n",
    "            plt.imshow(code_copyback.reshape(code_sides[0],code_sides[0]))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "            # display reconstruction\n",
    "            ax = plt.subplot(3, number, index + (number*2) + 1)\n",
    "            reconstruction = mixed_recon_g\n",
    "            recon_copyback = reconstruction[image_index]\n",
    "            plt.imshow(recon_copyback)\n",
    "            #plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        out_path = \"fail_output\" + full_extension + \".png\"\n",
    "        plt.savefig(out_path)\n",
    "        out_path = \"fail_output\" + full_extension + \".eps\"    \n",
    "        plt.savefig(out_path)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, plot projected error against reconstructed MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = np.where(predicted_class_np != 0)\n",
    "pred_0 = np.where(predicted_class_np == 0)\n",
    "\n",
    "mixed_error_set_np = np.asarray(mixed_error_set)\n",
    "mixed_error_0 = mixed_error_set_np[pred_0]\n",
    "mixed_error_1 = mixed_error_set_np[pred_1]\n",
    "\n",
    "post_losses_0 = np_post_losses[pred_0]\n",
    "post_losses_1 = np_post_losses[pred_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.title('Reconstruction relationship')\n",
    "plt.xlabel('Original Error')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.plot(mixed_error_0, post_losses_0, 'o', color='red');\n",
    "plt.plot(mixed_error_1, post_losses_1, 'o', color='blue');\n",
    "out_path = \"reconstruction_graph_output\" + full_extension + \".eps\"\n",
    "plt.savefig(out_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution histogram\n",
    "\n",
    "The high ROC can be explained by looking at the comparative distribution histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_np = np.stack(losses)\n",
    "print(len(post_losses_0))\n",
    "print(len(post_losses_1))\n",
    "print(len(losses_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Predicted Distribution histogram - MSE\")\n",
    "plt.xlabel(\"MSE\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.hist(losses_np,density=True,bins=80,color='green')\n",
    "plt.hist(post_losses_0,density=True,bins=80,color='blue')\n",
    "plt.hist(post_losses_1,density=True,bins=80,color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_1 = np.where(mixed_class_np != 0)\n",
    "base_0 = np.where(mixed_class_np == 0)\n",
    "\n",
    "mixed_error_set_np = np.asarray(mixed_error_set)\n",
    "mixed_error_0 = mixed_error_set_np[base_0]\n",
    "mixed_error_1 = mixed_error_set_np[base_1]\n",
    "\n",
    "base_losses_0 = mixed_losses_np[base_0]\n",
    "base_losses_1 = mixed_losses_np[base_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,8))\n",
    "plt.title(\"Base Distribution boxplot - MSE\")\n",
    "plt.xlabel(\"Distribution\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.boxplot((losses,base_losses_0,base_losses_1),labels=('Base','Real','Adversarial'))\n",
    "out_path = \"distribution_boxplot_output\" + full_extension + \".eps\"\n",
    "plt.savefig(out_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Actual Distribution histogram - MSE\")\n",
    "plt.xlabel(\"MSE\")\n",
    "plt.ylabel(\"Frequency Density\")\n",
    "\n",
    "#plt.hist(base_losses_0,density=True,bins=20,color='blue')\n",
    "\n",
    "plt.hist(losses_np,density=True,bins=80,color='green')\n",
    "plt.hist(base_losses_1,density=True,bins=80,color='red')\n",
    "out_path = \"distribution_hist_output\" + full_extension + \".eps\"\n",
    "plt.savefig(out_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
