{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing an Autoencoder in PyTorch\n",
    "===\n",
    "\n",
    "This is adapted from the workbook provided alongside the article \"Implementing an Autoencoder in Pytorch\" which can be found [here](https://medium.com/pytorch/implementing-an-autoencoder-in-pytorch-19baa22647d1). The primary differences are that the network is much larger (as the code is designed to work with much larger images) and the model is split into two parts to allow for differential encode/decode metrics such as Mahalanobis Distance.\n",
    "\n",
    "This version of the model is designed with a convolutional model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin by importing our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "import math\n",
    "import numpy\n",
    "import collections\n",
    "import gc\n",
    "\n",
    "from model import SplitAutoencoder,ExtensibleEncoder,ExtensibleDecoder\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import GPUtil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set our seed and other configurations for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "memory at beginning of run\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  2% |\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "#seed = 2521\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    platform = \"cuda\"\n",
    "else:\n",
    "    platform = \"cpu\"\n",
    "print(platform)\n",
    "\n",
    "print(\"memory at beginning of run\")\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the batch size, the number of training epochs, and the learning rate. Batch size has to be reasonably low as we can't fit a huge number of these images into VRAM on my laptop.\n",
    "\n",
    "Image size can be set here as I'm automatically resizing the images in my extraction code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "height = 256\n",
    "\n",
    "image_size = width * height\n",
    "\n",
    "epochs = 2\n",
    "learning_rate = 1e-5\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "#meta-parameters\n",
    "l2_decays = [0.1]\n",
    "dropout_rates = [0.0]\n",
    "code_sides = [16]\n",
    "convolution_filters = [32]\n",
    "\n",
    "image_count = 200\n",
    "#image_count = -1\n",
    "\n",
    "validation_split = 0.9\n",
    "\n",
    "early_stopping_bracket = 15\n",
    "early_stopping_forgiveness = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Using a custom dataset class to load the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsorted(all_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"F\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor,Grayscale\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(0.0,65535.0)\n",
    "    ])\n",
    "\n",
    "root_dir = \"../../Data/OPTIMAM_NEW/png_images/casewise/ScreeningMammography/256/detector\"\n",
    "#train_dataset = torchvision.datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "train_dataset = CustomDataSet(root_dir, transform)\n",
    "if (image_count == -1):\n",
    "    train_dataset_subset = train_dataset\n",
    "else:\n",
    "    train_dataset_subset = torch.utils.data.Subset(train_dataset, numpy.random.choice(len(train_dataset), image_count, replace=False))\n",
    "\n",
    "dataset_len = len(train_dataset_subset)\n",
    "indices = list(range(dataset_len))\n",
    "\n",
    "# Randomly splitting indices:\n",
    "val_len = int(np.floor((1.0 - validation_split) * dataset_len))\n",
    "\n",
    "dataset_size = len(train_dataset_subset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if 1 :\n",
    "    np.random.seed(1337)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, valid_indices = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset_subset, batch_size=batch_size, sampler = train_sampler\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset_subset, batch_size=batch_size, sampler = valid_sampler\n",
    ")\n",
    "\n",
    "data_loaders = {\"train\": train_loader, \"val\": valid_loader}\n",
    "data_lengths = {\"train\": split, \"val\": val_len}\n",
    "print(split)\n",
    "print(val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory before model construction\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  2% |\n",
      "memory after model construction\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  2% |\n"
     ]
    }
   ],
   "source": [
    "#  use gpu if available\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "run_device = torch.device(platform)\n",
    "store_device = torch.device(\"cpu\")\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "\n",
    "models = []\n",
    "optimizers = []\n",
    "\n",
    "print(\"memory before model construction\")\n",
    "GPUtil.showUtilization()\n",
    "\n",
    "\n",
    "for i in range(len(code_sides)):\n",
    "    models.append([])\n",
    "    optimizers.append([])\n",
    "    code_size = code_sides[i] * code_sides[i]\n",
    "    for j in range(len(convolution_filters)):\n",
    "        filters =  convolution_filters[j]\n",
    "        models[i].append([])\n",
    "        optimizers[i].append([])\n",
    "        for k in range(len(dropout_rates)):\n",
    "            dropout_rate = dropout_rates[k]\n",
    "            models[i][j].append([])\n",
    "            optimizers[i][j].append([])\n",
    "            for l in range(len(l2_decays)):\n",
    "                l2_decay = l2_decays[k]\n",
    "                new_model = SplitAutoencoder(input_shape=(height,width),code_size=code_size,convolutions=filters,dropout_chance=dropout_rate).to(store_device)\n",
    "                models[i][j][k].append(new_model)\n",
    "                optimizers[i][j][k].append(optim.Adam(new_model.parameters(), weight_decay=l2_decay, lr=learning_rate))\n",
    "\n",
    "print(\"memory after model construction\")\n",
    "GPUtil.showUtilization()\n",
    "# mean-squared error loss\n",
    "#criterion = nn.MSELoss(reduction='sum')\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "#criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a grid parameter search method to train our autoencoder for our specified number of epochs for each combination of code sizes and convolutional filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[(65535.0, None), (65535.0, None)], [(65535.0, None), (65535.0, None)]], [[(65535.0, None), (65535.0, None)], [(65535.0, None), (65535.0, None)]]], [[[(65535.0, None), (65535.0, None)], [(65535.0, None), (65535.0, None)]], [[(65535.0, None), (65535.0, None)], [(65535.0, None), (65535.0, None)]]], [[[(65535.0, None), (65535.0, None)], [(65535.0, None), (65535.0, None)]], [[(65535.0, None), (65535.0, None)], [(65535.0, None), (65535.0, None)]]]]\n"
     ]
    }
   ],
   "source": [
    "best_model_dicts = []\n",
    "# populate with fake best models\n",
    "for i in range(len(code_sides)):\n",
    "    best_model_dicts.append([])\n",
    "    for j in range(len(convolution_filters)):\n",
    "        best_model_dicts[i].append([])\n",
    "        for k in range(len(dropout_rates)):\n",
    "            best_model_dicts[i][j].append([])\n",
    "            for l in range(len(l2_decays)):\n",
    "                best_model_dicts[i][j][k].append((65535.0,None))\n",
    "print(best_model_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Running for code size:144, filter size:32with L1/dropout:0.1/0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chali\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py:92: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.float32, copy=False))\n",
      "C:\\Users\\chali\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:3060: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best!\n",
      "epoch : 1/2, train loss = 0.05363690, validation loss = 0.04990634\n",
      "epoch : 2/2, train loss = 0.05575515, validation loss = 0.04996525\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  5% | 28% |\n",
      "==================\n",
      "Running for code size:144, filter size:32with L1/dropout:0.0/0.2\n",
      "new best!\n",
      "epoch : 1/2, train loss = 0.05815845, validation loss = 0.04945260\n",
      "epoch : 2/2, train loss = 0.05497890, validation loss = 0.05004373\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 43% | 41% |\n",
      "==================\n",
      "Running for code size:144, filter size:32with L1/dropout:0.1/0.1\n",
      "new best!\n",
      "epoch : 1/2, train loss = 0.05427651, validation loss = 0.04937629\n",
      "new best!\n",
      "epoch : 2/2, train loss = 0.05501655, validation loss = 0.04844204\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 47% | 53% |\n",
      "==================\n",
      "Running for code size:144, filter size:32with L1/dropout:0.0/0.1\n",
      "new best!\n",
      "epoch : 1/2, train loss = 0.04444709, validation loss = 0.04097870\n",
      "new best!\n",
      "epoch : 2/2, train loss = 0.03880676, validation loss = 0.04005507\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 43% | 65% |\n",
      "==================\n",
      "Running for code size:144, filter size:16with L1/dropout:0.1/0.2\n",
      "new best!\n",
      "epoch : 1/2, train loss = 0.04156998, validation loss = 0.03816489\n",
      "epoch : 2/2, train loss = 0.04661956, validation loss = 0.03849857\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 42% | 65% |\n",
      "==================\n",
      "Running for code size:144, filter size:16with L1/dropout:0.0/0.2\n",
      "new best!\n",
      "epoch : 1/2, train loss = 0.04121999, validation loss = 0.03963916\n",
      "epoch : 2/2, train loss = 0.04158452, validation loss = 0.03992663\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 32% | 68% |\n",
      "==================\n",
      "Running for code size:144, filter size:16with L1/dropout:0.1/0.1\n",
      "new best!\n",
      "epoch : 1/2, train loss = 0.05756810, validation loss = 0.04962144\n",
      "epoch : 2/2, train loss = 0.05678782, validation loss = 0.04979463\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 74% |\n",
      "==================\n",
      "Running for code size:144, filter size:16with L1/dropout:0.0/0.1\n",
      "new best!\n",
      "epoch : 1/2, train loss = 0.05881446, validation loss = 0.04748051\n",
      "new best!\n",
      "epoch : 2/2, train loss = 0.05407135, validation loss = 0.04717896\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 80% |\n",
      "==================\n",
      "Running for code size:121, filter size:32with L1/dropout:0.1/0.2\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 6.00 GiB total capacity; 3.65 GiB already allocated; 48.91 MiB free; 4.10 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 85% |\n",
      "==================\n",
      "Running for code size:121, filter size:32with L1/dropout:0.0/0.2\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 6.00 GiB total capacity; 3.64 GiB already allocated; 48.91 MiB free; 4.10 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 85% |\n",
      "==================\n",
      "Running for code size:121, filter size:32with L1/dropout:0.1/0.1\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 6.00 GiB total capacity; 3.64 GiB already allocated; 48.91 MiB free; 4.10 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 85% |\n",
      "==================\n",
      "Running for code size:121, filter size:32with L1/dropout:0.0/0.1\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 6.00 GiB total capacity; 3.64 GiB already allocated; 48.91 MiB free; 4.10 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 85% |\n",
      "==================\n",
      "Running for code size:121, filter size:16with L1/dropout:0.1/0.2\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 6.00 GiB total capacity; 3.67 GiB already allocated; 16.91 MiB free; 4.13 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 85% |\n",
      "==================\n",
      "Running for code size:121, filter size:16with L1/dropout:0.0/0.2\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 6.00 GiB total capacity; 3.67 GiB already allocated; 16.91 MiB free; 4.13 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 85% |\n",
      "==================\n",
      "Running for code size:121, filter size:16with L1/dropout:0.1/0.1\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 6.00 GiB total capacity; 3.67 GiB already allocated; 16.91 MiB free; 4.13 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 85% |\n",
      "==================\n",
      "Running for code size:121, filter size:16with L1/dropout:0.0/0.1\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 6.00 GiB total capacity; 3.67 GiB already allocated; 16.91 MiB free; 4.13 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 85% |\n",
      "==================\n",
      "Running for code size:100, filter size:32with L1/dropout:0.1/0.2\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 6.00 GiB total capacity; 3.67 GiB already allocated; 14.91 MiB free; 4.14 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 85% |\n",
      "==================\n",
      "Running for code size:100, filter size:32with L1/dropout:0.0/0.2\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 6.00 GiB total capacity; 3.67 GiB already allocated; 14.91 MiB free; 4.14 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 85% |\n",
      "==================\n",
      "Running for code size:100, filter size:32with L1/dropout:0.1/0.1\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 6.00 GiB total capacity; 3.67 GiB already allocated; 14.91 MiB free; 4.14 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 85% |\n",
      "==================\n",
      "Running for code size:100, filter size:32with L1/dropout:0.0/0.1\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 6.00 GiB total capacity; 3.68 GiB already allocated; 14.91 MiB free; 4.14 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 85% |\n",
      "==================\n",
      "Running for code size:100, filter size:16with L1/dropout:0.1/0.2\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 6.00 GiB total capacity; 3.72 GiB already allocated; 14.91 MiB free; 4.14 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 35% | 85% |\n",
      "==================\n",
      "Running for code size:100, filter size:16with L1/dropout:0.0/0.2\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 6.00 GiB total capacity; 3.77 GiB already allocated; 12.91 MiB free; 4.14 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 85% |\n",
      "==================\n",
      "Running for code size:100, filter size:16with L1/dropout:0.1/0.1\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 6.00 GiB total capacity; 3.82 GiB already allocated; 12.91 MiB free; 4.14 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 85% |\n",
      "==================\n",
      "Running for code size:100, filter size:16with L1/dropout:0.0/0.1\n",
      "Can't complete this model due to:CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 6.00 GiB total capacity; 3.87 GiB already allocated; 12.91 MiB free; 4.14 GiB reserved in total by PyTorch)\n",
      "Memory at model end\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 85% |\n",
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "batch_features_n = torch.empty(batch_size, 1, width, height, dtype=torch.float32)\n",
    "for i in range(len(code_sides)):\n",
    "    train_losses.append([])\n",
    "    val_losses.append([])\n",
    "\n",
    "    for j in range(len(convolution_filters)):\n",
    "        train_losses[i].append([])\n",
    "        val_losses[i].append([])\n",
    "\n",
    "        for k in range(len(dropout_rates)):\n",
    "            train_losses[i][j].append([])\n",
    "            val_losses[i][j].append([])\n",
    "            for l in range(len(l2_decays)):\n",
    "                early_stopping_hits = 0\n",
    "                train_losses[i][j][k].append([])\n",
    "                val_losses[i][j][k].append([])\n",
    "                print(\"==================\")\n",
    "                print(\"Running for code size:\" + str(code_sides[i] * code_sides[i]) + \", filter size:\"+str(convolution_filters[j]) + \" with L2/dropout:\" + str(l2_decays[l]) + \"/\" + str(dropout_rates[k]))\n",
    "                try:\n",
    "                    model_n = models[i][j][k][l].to(run_device)\n",
    "                    if torch.cuda.device_count() > 1:\n",
    "                        model_n = nn.DataParallel(model_n)\n",
    "                    optimo = optimizers[i][j][k][l]\n",
    "                    for epoch in range(epochs):\n",
    "                        losses = {'train':0.0, 'val':0.0}\n",
    "\n",
    "                        for phase in ['train', 'val']:\n",
    "                            if phase == 'train':\n",
    "                                model_n.train()  # Set model to training mode\n",
    "                            else:\n",
    "                                model_n.eval()  # Set model to evaluate mode\n",
    "\n",
    "                            for batch_features in data_loaders[phase]:\n",
    "                                # load it to the active device\n",
    "                                batch_features_n = batch_features.to(run_device)\n",
    "\n",
    "                                # reset the gradients back to zero\n",
    "                                # PyTorch accumulates gradients on subsequent backward passes\n",
    "                                optimo.zero_grad()\n",
    "\n",
    "                                # compute reconstructions\n",
    "                                codes = model_n.encoder(batch_features_n)\n",
    "                                outputs = model_n.decoder(codes)\n",
    "\n",
    "                                # compute training reconstruction loss\n",
    "                                local_loss = criterion(outputs,batch_features_n)\n",
    "\n",
    "                                if phase == 'train':\n",
    "                                    # compute accumulated gradients\n",
    "                                    local_loss.backward()\n",
    "\n",
    "                                    # perform parameter update based on current gradients\n",
    "                                    optimo.step()\n",
    "\n",
    "                                # add the mini-batch training loss to epoch loss\n",
    "                                losses[phase] += local_loss.item()\n",
    "\n",
    "                                del local_loss\n",
    "                                del codes\n",
    "                                del outputs\n",
    "\n",
    "\n",
    "                        # compute the epoch training loss\n",
    "\n",
    "                        losses['train'] = losses['train'] / len(data_loaders['train'])\n",
    "                        losses['val'] = losses['val'] / len(data_loaders['val'])\n",
    "\n",
    "                        #check if best model\n",
    "                        if(losses['val'] < best_model_dicts[i][j][k][l][0]):\n",
    "                            print(\"new best!\")\n",
    "                            model_dict = {}\n",
    "                            for key, v in model_n.state_dict().items():\n",
    "                                  model_dict[key] = v.cpu()\n",
    "                            best_model_dicts[i][j][k][l] = (losses['val'],model_dict)\n",
    "\n",
    "                        train_losses[i][j][k][l].append(losses['train'])\n",
    "                        val_losses[i][j][k][l].append(losses['val'])\n",
    "\n",
    "                        # display the epoch training loss\n",
    "                        print(\"epoch : {}/{}, train loss = {:.8f}, validation loss = {:.8f}\".format(epoch + 1, epochs, losses['train'],losses['val']))\n",
    "\n",
    "                        #early stopping\n",
    "                        if(epoch>early_stopping_bracket+1):\n",
    "                            if(val_losses[i][j][k][l][epoch-early_stopping_bracket] <= losses['val']):\n",
    "                                # early stopping situation found. see if we need to stop yet\n",
    "                                early_stopping_hits = early_stopping_hits + 1\n",
    "                                if(early_stopping_hits > early_stopping_forgiveness):\n",
    "                                    print(\"Early stopping!\")\n",
    "                                    break\n",
    "                            else:\n",
    "                                if(early_stopping_hits > 0):\n",
    "                                    early_stopping_hits = early_stopping_hits - 1\n",
    "\n",
    "                    del model_n\n",
    "                    del optimo\n",
    "                    torch.cuda.empty_cache()\n",
    "                except RuntimeError as e:\n",
    "                    print(\"Can't complete this model due to:\" + str(e))\n",
    "                    model_n = None\n",
    "                    optimo = None\n",
    "\n",
    "                print(\"Memory at model end\")\n",
    "                GPUtil.showUtilization()\n",
    "\n",
    "print('\\a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the best trained model and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory before model restoration\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 85% |\n",
      "Restoring best model for 0/0/0/0\n",
      "Restoring best model for 0/0/0/1\n",
      "Restoring best model for 0/0/1/0\n",
      "Restoring best model for 0/0/1/1\n",
      "Restoring best model for 0/1/0/0\n",
      "Restoring best model for 0/1/0/1\n",
      "Restoring best model for 0/1/1/0\n",
      "Restoring best model for 0/1/1/1\n",
      "memory after model restoration\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 85% |\n"
     ]
    }
   ],
   "source": [
    "print(\"memory before model restoration\")\n",
    "GPUtil.showUtilization()\n",
    "#print(best_model_dicts)\n",
    "for i in range(len(code_sides)):\n",
    "    for j in range(len(convolution_filters)):\n",
    "        for k in range(len(dropout_rates)):\n",
    "            for l in range(len(l2_decays)):\n",
    "                if(best_model_dicts[i][j][k][l][1]!=None):\n",
    "                    print(\"Restoring best model for \"+ str(i) + \"/\" + str(j) + \"/\" + str(k) + \"/\" + str(l));\n",
    "                    models[i][j][k][l].load_state_dict(best_model_dicts[i][j][k][l][1], )\n",
    "                    PATH = \"../../Data/OPTIMAM_NEW/model\" + str(code_sides[i]) + \"_\" + str(convolution_filters[j]) + \"_\" + str(dropout_rates[k]) + \"_\" + str(l2_decays[l]) + \".pt\"\n",
    "                    torch.save(models[i][j][k][l], PATH)\n",
    "\n",
    "print(\"memory after model restoration\")\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract some test examples to reconstruct using our trained autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataSet(root_dir, transform) # same transform as we used for the training, for compatibility\n",
    "#test_dataset = train_dataset_subset\n",
    "if (image_count == -1):\n",
    "    test_dataset_subset = test_dataset\n",
    "else:\n",
    "    test_dataset_subset = torch.utils.data.Subset(test_dataset, numpy.random.choice(len(test_dataset), image_count, replace=False))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset_subset, batch_size=5, shuffle=True\n",
    ")\n",
    "\n",
    "test_example_sets = []\n",
    "code_sets = []\n",
    "reconstruction_sets = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Let's try to reconstruct some test images using our trained autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory before testing\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 85% |\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 6.00 GiB total capacity; 3.87 GiB already allocated; 12.91 MiB free; 4.14 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-79d46aad2377>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                             \u001b[0mtest_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                             \u001b[0mn_codes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                             \u001b[0mreconstruction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_codes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                             \u001b[1;32mbreak\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\PhD\\Code\\basic_autoencoder\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mcnnOutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnnStage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnnOutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 419\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 6.00 GiB total capacity; 3.87 GiB already allocated; 12.91 MiB free; 4.14 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "print(\"memory before testing\")\n",
    "GPUtil.showUtilization()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(code_sides)):\n",
    "        test_example_sets.append([])\n",
    "        code_sets.append([])\n",
    "        reconstruction_sets.append([])\n",
    "        \n",
    "        #test_example_sets.append([None] * len(convolution_filters))\n",
    "        #code_sets.append([None] * len(convolution_filters))\n",
    "        #reconstruction_sets.append([None] * len(convolution_filters))\n",
    "        for j in range(len(convolution_filters)):\n",
    "            test_example_sets[i].append([])\n",
    "            code_sets[i].append([])\n",
    "            reconstruction_sets[i].append([])\n",
    "            for k in range(len(dropout_rates)):\n",
    "                test_example_sets[i][j].append([None] * len(l2_decays))\n",
    "                code_sets[i][j].append([None] * len(l2_decays))\n",
    "                reconstruction_sets[i][j].append([None] * len(l2_decays))\n",
    "                for l in range(len(l2_decays)):\n",
    "                    if(best_model_dicts[i][j][k][l][1]!=None):\n",
    "                        model_t = models[i][j][k][l].to(run_device)\n",
    "                        for batch_features in test_loader:\n",
    "                            test_examples = batch_features.to(run_device)\n",
    "                            n_codes = model_t.encoder(test_examples)\n",
    "                            reconstruction = model_t.decoder(n_codes)\n",
    "                            break;\n",
    "                        test_example_sets[i][j][k][l] = test_examples.to(store_device)\n",
    "                        code_sets[i][j][k][l] = n_codes.to(store_device)\n",
    "                        reconstruction_sets[i][j][k][l] = reconstruction.to(store_device)\n",
    "                        del test_examples\n",
    "                        del n_codes\n",
    "                        del reconstruction\n",
    "print(\"memory after testing\")\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(len(code_sides)):\n",
    "        for j in range(len(convolution_filters)):\n",
    "            for k in range(len(dropout_rates)):\n",
    "                for l in range(len(l2_decays)):\n",
    "                    if(best_model_dicts[i][j][k][l][1]!=None):\n",
    "                        number = 5\n",
    "                        plt.figure(figsize=(25, 9))\n",
    "                        for index in range(number):\n",
    "                            # display original\n",
    "                            ax = plt.subplot(3, number, index + 1)\n",
    "                            test_examples = test_example_sets[i][j][k][l]\n",
    "                            copyback = test_examples[index].cpu()\n",
    "                            #plt.imshow(copyback.numpy().reshape(height, width), vmin=0, vmax=65535)\n",
    "                            plt.imshow(copyback.reshape(height, width))\n",
    "                            plt.gray()\n",
    "                            ax.get_xaxis().set_visible(False)\n",
    "                            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "                            # display codes\n",
    "                            ax = plt.subplot(3, number, index + 1 + number)\n",
    "                            codes = code_sets[i][j][k][l]\n",
    "                            code_copyback = codes[index].cpu()\n",
    "                            plt.imshow(code_copyback.numpy().reshape(code_sides[i],code_sides[i]))\n",
    "                            plt.gray()\n",
    "                            ax.get_xaxis().set_visible(False)\n",
    "                            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "                            # display reconstruction\n",
    "                            ax = plt.subplot(3, number, index + 6 + number)\n",
    "                            reconstruction = reconstruction_sets[i][j][k][l]\n",
    "                            recon_copyback = reconstruction[index].cpu()\n",
    "                            plt.imshow(recon_copyback.reshape(height, width))\n",
    "                            plt.gray()\n",
    "                            ax.get_xaxis().set_visible(False)\n",
    "                            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "                        out_path = \"output\" + str(code_sides([i]) + \"_\" + str(convolution_filters[j]) + \"_\" + str(dropout_rates[k]) + \"_\" + str(l2_decays[l]) +\".png\" \n",
    "                        plt.savefig(out_path)\n",
    "                        #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
