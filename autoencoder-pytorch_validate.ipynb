{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing an Autoencoder in PyTorch\n",
    "===\n",
    "\n",
    "This is adapted from the workbook provided alongside the article \"Implementing an Autoencoder in Pytorch\" which can be found [here](https://medium.com/pytorch/implementing-an-autoencoder-in-pytorch-19baa22647d1). The primary differences are that the network is much larger (as the code is designed to work with much larger images) and the model is split into two parts to allow for differential encode/decode metrics such as Mahalanobis Distance.\n",
    "\n",
    "This version of the model is designed with a convolutional model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin by importing our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "import math\n",
    "import numpy\n",
    "\n",
    "from model import SplitAutoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set our seed and other configurations for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    platform = \"cuda\"\n",
    "else:\n",
    "    platform = \"cpu\"\n",
    "print(platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the batch size, the number of training epochs, and the learning rate. Batch size has to be reasonably low as we can't fit a huge number of these images into VRAM on my laptop.\n",
    "\n",
    "Image size can be set here as I'm automatically resizing the images in my extraction code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1024\n",
    "height = 1024\n",
    "\n",
    "image_size = width * height\n",
    "\n",
    "batch_size = 12\n",
    "epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "#code_size = 100\n",
    "code_sides = [10]\n",
    "\n",
    "convolution_filters = 8\n",
    "\n",
    "image_count = 500\n",
    "#image_count = -1\n",
    "\n",
    "validation_split = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "ImageFolder is used to load the base distribution images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torchvision.transforms import ToTensor,Grayscale\n",
    "transform = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.Grayscale(),\n",
    "     torchvision.transforms.Resize((height,width)),\n",
    "     torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "root_dir = \"../../Data/OPTIMAM_NEW/png_images\"\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "if (image_count == -1):\n",
    "    train_dataset_subset = train_dataset\n",
    "else:\n",
    "    train_dataset_subset = torch.utils.data.Subset(train_dataset, numpy.random.choice(len(train_dataset), image_count, replace=False))\n",
    "\n",
    "dataset_len = len(train_dataset_subset)\n",
    "indices = list(range(dataset_len))\n",
    "\n",
    "# Randomly splitting indices:\n",
    "val_len = int(np.floor((1.0 - validation_split) * dataset_len))\n",
    "\n",
    "dataset_size = len(train_dataset_subset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if 1 :\n",
    "    np.random.seed(1337)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, valid_indices = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset_subset, batch_size=batch_size, sampler = train_sampler\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset_subset, batch_size=batch_size, sampler = valid_sampler\n",
    ")\n",
    "\n",
    "data_loaders = {\"train\": train_loader, \"val\": valid_loader}\n",
    "data_lengths = {\"train\": split, \"val\": val_len}\n",
    "print(split)\n",
    "print(val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use gpu if available\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(platform)\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "\n",
    "models = []\n",
    "optimizers = []\n",
    "\n",
    "for i in range(len(code_sides)):\n",
    "    code_size = code_sides[i] * code_sides[i]\n",
    "    models.append(SplitAutoencoder(input_shape=(height,width),code_size=code_size,convolutions=convolution_filters).to(device))\n",
    "    optimizers.append(optim.Adam(models[i].parameters(), lr=learning_rate))\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our autoencoder for our specified number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(code_sides)):\n",
    "    print(\"==================\")\n",
    "    print(\"Running for code size:\" + str(code_sides[i] * code_sides[i]))\n",
    "    for epoch in range(epochs):\n",
    "        losses = {'train':0.0, 'val':0.0}\n",
    "       \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                models[i].train()  # Set model to training mode\n",
    "            else:\n",
    "                models[i].eval()  # Set model to evaluate mode\n",
    "\n",
    "            for batch_features, labels in data_loaders[phase]:\n",
    "                # load it to the active device\n",
    "                batch_features = batch_features.to(device)\n",
    "\n",
    "                # reset the gradients back to zero\n",
    "                # PyTorch accumulates gradients on subsequent backward passes\n",
    "                optimizers[i].zero_grad()\n",
    "\n",
    "                # compute reconstructions\n",
    "                codes = models[i].encoder(batch_features)\n",
    "                outputs = models[i].decoder(codes)\n",
    "\n",
    "                # compute training reconstruction loss\n",
    "                local_loss = criterion(outputs,batch_features)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    # compute accumulated gradients\n",
    "                    local_loss.backward()\n",
    "\n",
    "                    # perform parameter update based on current gradients\n",
    "                    optimizers[i].step()\n",
    "\n",
    "                # add the mini-batch training loss to epoch loss\n",
    "                losses[phase] += local_loss.item()\n",
    "\n",
    "        # compute the epoch training loss\n",
    "        #losses['train'] = losses['train'] / data_lengths['train']\n",
    "        #losses['val'] = losses['val'] / data_lengths['val']\n",
    "\n",
    "        losses['train'] = losses['train'] / len(data_loaders['train'])\n",
    "        losses['val'] = losses['val'] / len(data_loaders['val'])\n",
    "\n",
    "        \n",
    "        # display the epoch training loss\n",
    "        print(\"epoch : {}/{}, train loss = {:.8f}, validation loss = {:.8f}\".format(epoch + 1, epochs, losses['train'],losses['val']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(code_sides)):\n",
    "    PATH = \"../../Data/OPTIMAM_NEW/model\" + str(i) + \".pt\"\n",
    "    torch.save(models[i], PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract some test examples to reconstruct using our trained autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../../Data/OPTIMAM_NEW/png_images\"\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=root_dir, transform=transform) # same transform as we used for the training, for compatibility\n",
    "\n",
    "if (image_count == -1):\n",
    "    test_dataset_subset = test_dataset\n",
    "else:\n",
    "    test_dataset_subset = torch.utils.data.Subset(test_dataset, numpy.random.choice(len(test_dataset), image_count, replace=False))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset_subset, batch_size=5, shuffle=True\n",
    ")\n",
    "\n",
    "test_example_sets = [None] * len(code_sides)\n",
    "code_sets = [None] * len(code_sides)\n",
    "reconstruction_sets = [None] * len(code_sides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Let's try to reconstruct some test images using our trained autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(len(code_sides)):\n",
    "        for batch_features in test_loader:\n",
    "            batch_features = batch_features[0]\n",
    "            test_examples = batch_features.to(device)\n",
    "            n_codes = models[i].encoder(test_examples)\n",
    "            reconstruction = models[i](test_examples)\n",
    "            break;\n",
    "        test_example_sets[i] = test_examples\n",
    "        code_sets[i] = n_codes\n",
    "        reconstruction_sets[i] = reconstruction\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(len(code_sides)):\n",
    "        number = 5\n",
    "        plt.figure(figsize=(25, 9))\n",
    "        for index in range(number):\n",
    "            # display original\n",
    "            ax = plt.subplot(3, number, index + 1)\n",
    "            test_examples = test_example_sets[i]\n",
    "            copyback = test_examples[index].cpu()\n",
    "            plt.imshow(copyback.numpy().reshape(height, width))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "            # display codes\n",
    "            ax = plt.subplot(3, number, index + 1 + number)\n",
    "            codes = code_sets[i]\n",
    "            code_copyback = codes[index].cpu()\n",
    "            plt.imshow(code_copyback.numpy().reshape(code_sides[i],code_sides[i]))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "            # display reconstruction\n",
    "            ax = plt.subplot(3, number, index + 6 + number)\n",
    "            reconstruction = reconstruction_sets[i]\n",
    "            recon_copyback = reconstruction[index].cpu()\n",
    "            plt.imshow(recon_copyback.numpy().reshape(height, width))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "        out_path = \"output\"+str(i)+\".png\" \n",
    "        plt.savefig(out_path)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
