{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Plotting Fixes\n",
    "===\n",
    "\n",
    "We modified the processing script to correctly handle 12-bit images in the DICOM files, and output them as 16-bit PNG images. However we're having some problem with displaying the reprocessed images. This workbook is intended to examine these images and the autoencoder output corresponding to them, to determine if there is anything that can be done with them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin by importing our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "import math\n",
    "import numpy\n",
    "import collections\n",
    "\n",
    "from model import SplitAutoencoder,ExtensibleEncoder,ExtensibleDecoder\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set our seed and other configurations for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    platform = \"cuda\"\n",
    "else:\n",
    "    platform = \"cpu\"\n",
    "print(platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the batch size, the number of training epochs, and the learning rate. Batch size has to be reasonably low as we can't fit a huge number of these images into VRAM on my laptop.\n",
    "\n",
    "Image size can be set here as I'm automatically resizing the images in my extraction code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "height = 256\n",
    "\n",
    "image_size = width * height\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 80\n",
    "learning_rate = 1e-4\n",
    "\n",
    "#code_size = 100\n",
    "code_sides = [16]\n",
    "\n",
    "convolution_filters = 4\n",
    "\n",
    "#image_count = 300\n",
    "image_count = -1\n",
    "\n",
    "validation_split = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Using a custom dataset class to load the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsorted(all_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"F\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3309\n",
      "367\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torchvision.transforms import ToTensor,Grayscale\n",
    "transform = torchvision.transforms.Compose([\n",
    "#    torchvision.transforms.Lambda(lambda image: torch.from_numpy(numpy.array(image).astype(numpy.float32)).unsqueeze(0))\n",
    "    torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize(0.0,65535.0)\n",
    "#     torchvision.transforms.Resize((height,width)),\n",
    "    ])\n",
    "\n",
    "root_dir = \"../../Data/OPTIMAM_NEW/png_images/casewise/ScreeningMammography/256/detector\"\n",
    "#train_dataset = torchvision.datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "train_dataset = CustomDataSet(root_dir, transform)\n",
    "if (image_count == -1):\n",
    "    train_dataset_subset = train_dataset\n",
    "else:\n",
    "    train_dataset_subset = torch.utils.data.Subset(train_dataset, numpy.random.choice(len(train_dataset), image_count, replace=False))\n",
    "\n",
    "dataset_len = len(train_dataset_subset)\n",
    "indices = list(range(dataset_len))\n",
    "\n",
    "# Randomly splitting indices:\n",
    "val_len = int(np.floor((1.0 - validation_split) * dataset_len))\n",
    "\n",
    "dataset_size = len(train_dataset_subset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if 1 :\n",
    "    np.random.seed(1337)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, valid_indices = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset_subset, batch_size=batch_size, sampler = train_sampler\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset_subset, batch_size=batch_size, sampler = valid_sampler\n",
    ")\n",
    "\n",
    "data_loaders = {\"train\": train_loader, \"val\": valid_loader}\n",
    "data_lengths = {\"train\": split, \"val\": val_len}\n",
    "print(split)\n",
    "print(val_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a few of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256) 1.0 0.0 0.13029957 0.15910603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chali\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py:92: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.float32, copy=False))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(25, 9))\n",
    "# display original\n",
    "ax = plt.subplot(3, 5, 1)\n",
    "#print(train_dataset_subset[735][0])\n",
    "copyback = train_dataset_subset[735][0].numpy()\n",
    "print(copyback.shape, copyback.max(), copyback.min(), copyback.mean(), copyback.std())\n",
    "#print(copyback)\n",
    "#plt.imshow(copyback.reshape(height, width), vmin=0, vmax=65535.0)\n",
    "plt.imshow(copyback.reshape(height, width))\n",
    "#plt.imshow(copyback)\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplitAutoencoder(\n",
       "  (encoder): ExtensibleEncoder(\n",
       "    (cnnStage): Sequential(\n",
       "      (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu1): ReLU()\n",
       "      (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv2): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU()\n",
       "      (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu3): ReLU()\n",
       "      (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (fc1): Linear(in_features=65536, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): ExtensibleDecoder(\n",
       "    (cnnStage): Sequential(\n",
       "      (conv3): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu3): ReLU()\n",
       "      (upsample3): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "      (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU()\n",
       "      (upsample2): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu1): ReLU()\n",
       "      (upsample1): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    )\n",
       "    (fc1): Linear(in_features=256, out_features=65536, bias=True)\n",
       "    (unflatten): Unflatten(dim=1, unflattened_size=(64, 32, 32))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  use gpu if available\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(platform)\n",
    "model_path = \"../../Data/OPTIMAM_NEW/model0.pt\"\n",
    "model = torch.load(model_path,map_location=torch.device(\"cuda\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract some test examples to reconstruct using our trained autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataSet(root_dir, transform) # same transform as we used for the training, for compatibility\n",
    "\n",
    "if (image_count == -1):\n",
    "    test_dataset_subset = test_dataset\n",
    "else:\n",
    "    test_dataset_subset = torch.utils.data.Subset(test_dataset, numpy.random.choice(len(test_dataset), image_count, replace=False))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset_subset, batch_size=5, shuffle=True\n",
    ")\n",
    "\n",
    "test_example_sets = [None] * len(code_sides)\n",
    "code_sets = [None] * len(code_sides)\n",
    "reconstruction_sets = [None] * len(code_sides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Let's try to reconstruct some test images using our trained autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [4, 1, 3, 3], but got 3-dimensional input of size [1, 256, 256] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-df290df21433>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mbatch_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtest_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mn_codes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mreconstruction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\PhD\\Code\\basic_autoencoder\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mcnnOutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnnStage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnnOutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 419\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [4, 1, 3, 3], but got 3-dimensional input of size [1, 256, 256] instead"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_features in test_loader:\n",
    "        batch_features = batch_features[0]\n",
    "        test_examples = batch_features.to(device)\n",
    "        n_codes = model.encoder(test_examples)\n",
    "        reconstruction = model(test_examples)\n",
    "        break;\n",
    "    test_example_sets = test_examples\n",
    "    code_sets = n_codes\n",
    "    reconstruction_sets = reconstruction\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    number = 5\n",
    "    plt.figure(figsize=(25, 9))\n",
    "    for index in range(number):\n",
    "        # display original\n",
    "        ax = plt.subplot(3, number, index + 1)\n",
    "        test_examples = test_example_sets\n",
    "        copyback = test_examples[index].cpu()\n",
    "        #plt.imshow(copyback.numpy().reshape(height, width), vmin=0, vmax=4096)\n",
    "        #plt.imshow(copyback.reshape(height, width))\n",
    "        plt.imshow(copyback)\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display codes\n",
    "        ax = plt.subplot(3, number, index + 1 + number)\n",
    "        codes = code_sets\n",
    "        code_copyback = codes[index].cpu()\n",
    "        plt.imshow(code_copyback.numpy().reshape(code_sides[0],code_sides[0]))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(3, number, index + 6 + number)\n",
    "        reconstruction = reconstruction_sets\n",
    "        recon_copyback = reconstruction[index].cpu()\n",
    "        #plt.imshow(recon_copyback.reshape(height, width), vmin=0, vmax=4096)\n",
    "        plt.imshow(recon_copyback.reshape(height, width))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    out_path = \"output\"+str(0)+\".png\" \n",
    "    plt.savefig(out_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
