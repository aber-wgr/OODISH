{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting And Extending Autoencoder Networks in Pytorch\n",
    "===\n",
    "\n",
    "This is adapted from the workbook provided alongside the article \"Implementing an Autoencoder in Pytorch\" which can be found [here](https://medium.com/pytorch/implementing-an-autoencoder-in-pytorch-19baa22647d1). The purpose of this workbook is to load the generated networks, read the parameters from the network, then extend the network to work with larger images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin by importing our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as  optim\n",
    "import torchvision\n",
    "import math\n",
    "\n",
    "import collections\n",
    "\n",
    "from model import SplitAutoencoder,ExtensibleEncoder,ExtensibleDecoder\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set our seed and other configurations for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "platform = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if platform=='cuda' else {}\n",
    "\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    platform = \"cuda\"\n",
    "#else:\n",
    "#    platform = \"cpu\"\n",
    "platform = \"cpu\"\n",
    "print(platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the batch size, the number of training epochs, and the learning rate. Batch size has to be reasonably low as we can't fit a huge number of these images into VRAM on my laptop.\n",
    "\n",
    "Image size can be set here as I'm automatically resizing the images in my extraction code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_width = 256\n",
    "base_height = 256\n",
    "\n",
    "extended_width = 2048\n",
    "extended_height = 2048\n",
    "\n",
    "image_size = extended_width * extended_height\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 30\n",
    "learning_rate = 1e-4\n",
    "\n",
    "code_sides = [16]\n",
    "\n",
    "model_path = \"../../Data/OPTIMAM_NEW/model0.pt\"\n",
    "\n",
    "#image_count = 500\n",
    "image_count = -1\n",
    "\n",
    "validation_split = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "ImageFolder is now used to load the 2048x2048 versions of the images. This version of the DataLoader setup is designed to not batch or shuffle the images as we load them sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torchvision.transforms import ToTensor,Grayscale\n",
    "transform = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.Grayscale(),\n",
    "#     torchvision.transforms.Resize((height,width)),\n",
    "     torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "root_dir = \"../../Data/OPTIMAM_NEW/png_images/casewise/ScreeningMammography/2048\"\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "if (image_count == -1):\n",
    "    train_dataset_subset = train_dataset\n",
    "    image_count = len(train_dataset)\n",
    "    print(\"setting image count to \" + str(image_count))\n",
    "else:\n",
    "    train_dataset_subset = torch.utils.data.Subset(train_dataset, numpy.random.choice(len(train_dataset), image_count, replace=False))\n",
    "\n",
    "dataset_len = len(train_dataset_subset)\n",
    "indices = list(range(dataset_len))\n",
    "\n",
    "# Randomly splitting indices:\n",
    "val_len = int(np.floor((1.0 - validation_split) * dataset_len))\n",
    "\n",
    "dataset_size = len(train_dataset_subset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if 1 :\n",
    "    np.random.seed(1337)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, valid_indices = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset_subset, batch_size=batch_size, sampler = train_sampler\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset_subset, batch_size=batch_size, sampler = valid_sampler\n",
    ")\n",
    "\n",
    "data_loaders = {\"train\": train_loader, \"val\": valid_loader}\n",
    "data_lengths = {\"train\": split, \"val\": val_len}\n",
    "print(split)\n",
    "print(val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use gpu if available\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(platform)\n",
    "\n",
    "# reload the saved model\n",
    "\n",
    "code_size = code_sides[0] * code_sides[0]\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the saved 256x256 model to CPU-side (we'll load the extended version to GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_path,map_location=torch.device(\"cuda\"))\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And adapt it to 2048x2048 mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reconstruct_to((extended_height,extended_width))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the reconstructed model for our selected number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_dicts = []\n",
    "# populate with fake best models\n",
    "for i in range(len(code_sides)):\n",
    "    best_model_dicts.append((1.0,None))\n",
    "\n",
    "models = [model]\n",
    "optimizers = [optim.Adam(models[i].parameters(), lr=learning_rate)]\n",
    "    \n",
    "train_losses = []\n",
    "val_losses = []\n",
    "    \n",
    "i=0\n",
    "print(\"==================\")\n",
    "print(\"Running for code size:\" + str(code_sides[i] * code_sides[i]))\n",
    "\n",
    "train_losses.append([])\n",
    "val_losses.append([])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = {'train':0.0, 'val':0.0}\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            models[i].train()  # Set model to training mode\n",
    "        else:\n",
    "            models[i].eval()  # Set model to evaluate mode\n",
    "\n",
    "        for batch_features, labels in data_loaders[phase]:\n",
    "            # load it to the active device\n",
    "            batch_features = batch_features.to(device)\n",
    "\n",
    "            # reset the gradients back to zero\n",
    "            # PyTorch accumulates gradients on subsequent backward passes\n",
    "            optimizers[i].zero_grad()\n",
    "\n",
    "            # compute reconstructions\n",
    "            codes = models[i].encoder(batch_features)\n",
    "            outputs = models[i].decoder(codes)\n",
    "\n",
    "            # compute training reconstruction loss\n",
    "            local_loss = criterion(outputs,batch_features)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # compute accumulated gradients\n",
    "                local_loss.backward()\n",
    "\n",
    "                # perform parameter update based on current gradients\n",
    "                optimizers[i].step()\n",
    "\n",
    "            # add the mini-batch training loss to epoch loss\n",
    "            losses[phase] += local_loss.item()\n",
    "\n",
    "    # compute the epoch training loss\n",
    "    #losses['train'] = losses['train'] / data_lengths['train']\n",
    "    #losses['val'] = losses['val'] / data_lengths['val']\n",
    "\n",
    "    losses['train'] = losses['train'] / len(data_loaders['train'])\n",
    "    losses['val'] = losses['val'] / len(data_loaders['val'])\n",
    "\n",
    "    #check if best model\n",
    "    if(losses['val'] < best_model_dicts[i][0]):\n",
    "        best_model_dicts[i] = (losses['val'],models[i].state_dict())\n",
    "\n",
    "    train_losses.append(losses['train'])\n",
    "    val_losses.append(losses['val'])\n",
    "\n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, train loss = {:.8f}, validation loss = {:.8f}\".format(epoch + 1, epochs, losses['train'],losses['val']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
