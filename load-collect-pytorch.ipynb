{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting Network Statistics in Pytorch\n",
    "===\n",
    "\n",
    "This is adapted from the workbook provided alongside the article \"Implementing an Autoencoder in Pytorch\" which can be found [here](https://medium.com/pytorch/implementing-an-autoencoder-in-pytorch-19baa22647d1). The purpose is to load generated trained models from the Autoencoder implementation and collect encoding statistics for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin by importing our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import math\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set our seed and other configurations for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    platform = \"cuda\"\n",
    "#else:\n",
    "#    platform = \"cpu\"\n",
    "platform = \"cpu\"\n",
    "print(platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the batch size, the number of training epochs, and the learning rate. Batch size has to be reasonably low as we can't fit a huge number of these images into VRAM on my laptop.\n",
    "\n",
    "Image size can be set here as I'm automatically resizing the images in my extraction code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 256\n",
    "height = 256\n",
    "\n",
    "image_size = width * height\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "code_sides = [16]\n",
    "\n",
    "model_path = \"../../Data/OPTIMAM_NEW/model0.pt\"\n",
    "\n",
    "#image_count = 500\n",
    "image_count = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "ImageFolder is used to load the base distribution images. This version of the DataLoader setup is designed to not batch or shuffle the images as we load them sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torchvision.transforms import ToTensor,Grayscale\n",
    "transform = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.Grayscale(),\n",
    "     torchvision.transforms.Resize((height,width)),\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     #torchvision.transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "\n",
    "root_dir = \"../../Data/OPTIMAM_NEW/png_images\"\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "if (image_count == -1):\n",
    "    train_dataset_subset = train_dataset\n",
    "    image_count = len(train_dataset)\n",
    "    print(\"setting image count to \" + str(image_count))\n",
    "else:\n",
    "    train_dataset_subset = torch.utils.data.Subset(train_dataset, numpy.random.choice(len(train_dataset), image_count, replace=False))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset_subset, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder\n",
    "\n",
    "We have to load the same encoding setup as in our autoencoder. (We'll set this up as an include in a bit.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitAutoencoder(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential( \n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 128x128x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 64x64x64\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 32x32x128\n",
    "            nn.Flatten(), # 131072x1\n",
    "            nn.Linear(in_features=32*32*128,out_features=kwargs[\"code_size\"]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # result (encoding) is code_size x 1\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=kwargs[\"code_size\"], out_features=32*32*128), #131072x1\n",
    "            nn.Unflatten(1,(128,32,32)), # 32x32x128\n",
    "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'), # 64x64x64\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'), # 128x128x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'), #256x256x1\n",
    "        )\n",
    "        \n",
    "    def forward(self, features):\n",
    "        code = self.encoder(features)\n",
    "        out = self.decoder(code)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using our defined autoencoder class, we have the following things to do:\n",
    "    1. We configure which device we want to run on.\n",
    "    2. We instantiate our modules.\n",
    "    3. We define our optimizer.\n",
    "    4. We define our reconstruction loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use gpu if available\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(platform)\n",
    "\n",
    "# reload the saved model\n",
    "\n",
    "model = torch.load(model_path,map_location=device)\n",
    "model.eval()\n",
    "\n",
    "code_size = code_sides[0] * code_sides[0]\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.BCELoss()\n",
    "\n",
    "losses = [None] * len(train_dataset_subset)\n",
    "encodings = [None] * len(train_dataset_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run our autoencoder on the entire dataset and store the encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for batch_features, labels in train_loader:\n",
    "        print(\"Feature Batch:\" + str(count) + \" Labels:\" + str(labels[0]))\n",
    "        # load it to the active device\n",
    "        batch_features = batch_features.to(device)\n",
    "\n",
    "        # compute reconstructions\n",
    "        code = model.encoder(batch_features)\n",
    "        outputs = model.decoder(code)\n",
    "        \n",
    "        code_reshaped = code.detach().numpy()[0]\n",
    "        code_reshaped.reshape(code_size)\n",
    "\n",
    "        encodings[count] = code_reshaped\n",
    "\n",
    "        # compute training reconstruction loss\n",
    "        error_criterion = criterion(outputs,batch_features)\n",
    "\n",
    "        losses[count] = error_criterion.numpy()\n",
    "\n",
    "        count = count + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the compiled statistics to an excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    np_losses = np.asarray(losses)\n",
    "\n",
    "    np_compiled = np.concatenate((np_losses[:, np.newaxis], encodings), axis=1)\n",
    "\n",
    "    np.savetxt('encodings.csv', encodings, delimiter=',',fmt='%10.5f',newline='\\n')\n",
    "    np.savetxt('losses.csv', np_losses, delimiter=',',fmt='%10.5f',newline='\\n')\n",
    "    np.savetxt('combined.csv', np_compiled, delimiter=',',fmt='%10.5f',newline='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Let's try to reconstruct some test images using our trained autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(len(code_sides)):\n",
    "        for batch_features in test_loader:\n",
    "            batch_features = batch_features[0]\n",
    "            test_examples = batch_features.to(device)\n",
    "            n_codes = models[i].encoder(test_examples)\n",
    "            reconstruction = models[i](test_examples)\n",
    "            break;\n",
    "        test_example_sets[i] = test_examples\n",
    "        code_sets[i] = n_codes\n",
    "        reconstruction_sets[i] = reconstruction\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(len(code_sides)):\n",
    "        number = 5\n",
    "        plt.figure(figsize=(25, 9))\n",
    "        for index in range(number):\n",
    "            # display original\n",
    "            ax = plt.subplot(3, number, index + 1)\n",
    "            test_examples = test_example_sets[i]\n",
    "            copyback = test_examples[index].cpu()\n",
    "            plt.imshow(copyback.numpy().reshape(height, width))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "            # display codes\n",
    "            ax = plt.subplot(3, number, index + 1 + number)\n",
    "            codes = code_sets[i]\n",
    "            code_copyback = codes[index].cpu()\n",
    "            plt.imshow(code_copyback.numpy().reshape(code_sides[i],code_sides[i]))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "            # display reconstruction\n",
    "            ax = plt.subplot(3, number, index + 6 + number)\n",
    "            reconstruction = reconstruction_sets[i]\n",
    "            recon_copyback = reconstruction[index].cpu()\n",
    "            plt.imshow(recon_copyback.numpy().reshape(height, width))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "        out_path = \"output\"+str(i)+\".png\" \n",
    "        plt.savefig(out_path)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
